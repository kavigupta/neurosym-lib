{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Neurosymbolic Software Tutorial - Discrete\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/kavigupta/neurosym-lib/blob/main/tutorial/discrete_exercise_skeleton.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\n",
        "## Instruction\n",
        "- Navigating this notebook on Google Colab: There will be text blocks and code blocks throughout the notebook. The text blocks, such as this one, will contain instructions and questions for you to consider. The code blocks, such as the one below, will contain executible code. Sometimes you will have to modify the code blocks following the instructions in the text blocks. You can run the code block by either pressing control/cmd + enter or by clicking the arrow on left-hand side.\n",
        "- Saving Work: If you wish to save your work in this .ipynb, we recommend downloading the compressed repository from GitHub, unzipping it, uploading it to Google Drive, and opening this notebook from within Google Drive.\n",
        "\n",
        "\n",
        "## Outline\n",
        "\n",
        "- Part 1: Defining a DSL\n",
        "- Part 2: Finding Programs\n",
        "- Part 3: Abstraction Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "\n",
        "import itertools\n",
        "import neurosym as ns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"error\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 1: Defining a DSL\n",
        "\n",
        "We would like to be able to define arithmetic functions, of various types.\n",
        "\n",
        "### Exercise 1A: Create a DSL\n",
        "\n",
        "We would like our DSL to be able to represent the following functions. **For future experiments, make sure you don't include cosine.**\n",
        "\n",
        "- $f_0(x) = x + 1$\n",
        "- $f_1(x) = x^2 + \\frac{x}{\\sin x}$\n",
        "- $f_2(x) = (x + 2)^x$\n",
        "- $f_3(x) = \\begin{cases}\n",
        "x^2 & x < 0\\\\\n",
        "\\sqrt {x^2 + 1} & x \\geq 0\\\\\n",
        "\\end{cases}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "dslf = ns.DSLFactory()\n",
        "dslf.concrete(\"0\", \"() -> f\", lambda: 0)\n",
        "dslf.concrete(\"1\", \"() -> f\", lambda: 1)\n",
        "dslf.concrete(\"2\", \"() -> f\", lambda: 2)\n",
        "dslf.concrete(\"+\", \"(f, f) -> f\", lambda x, y: x + y)\n",
        "dslf.concrete(\"-\", \"(f, f) -> f\", lambda x, y: x - y)\n",
        "\"YOUR CODE HERE\"\n",
        "dslf.lambdas()\n",
        "dslf.prune_to(\"f -> f\")\n",
        "dsl = dslf.finalize()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### DSL Printout\n",
        "\n",
        "See your DSL printed below, and ensure it is what you would expect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(dsl.render())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 1B: Write your functions\n",
        "\n",
        "We have provided $f_0$, it is up to you to write $f_1$ through $f_3$. Note that there are no leaf nodes in the neurosym DSLs, so terminal productions are represented as s-expressions with no children. Run the tests in the following cell to make sure your DSL and programs are working properly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "f_0 = \"(lam (+ ($0_0) (1)))\"\n",
        "\"YOUR CODE HERE\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_program(actual_program, expected_fn):\n",
        "    actual_fn = dsl.compute(dsl.initialize(ns.parse_s_expression(actual_program)))\n",
        "    inputs = np.linspace(-1, 1, 100)\n",
        "    actual = np.array([actual_fn(x) for x in inputs])\n",
        "    expected = np.array([expected_fn(x) for x in inputs])\n",
        "    delta = np.abs(actual - expected)\n",
        "    bad = delta > 1e-5\n",
        "    if (~bad).all():\n",
        "        return\n",
        "    [[bad_input, *_]] = np.where(bad)\n",
        "    raise AssertionError(f\"On input {inputs[bad_input]}, expected {expected[bad_input]} but recvd {actual[bad_input]}\")\n",
        "\n",
        "test_program(f_0, lambda x: x + 1)\n",
        "test_program(f_1, lambda x: x ** 2 + x / np.sin(x))\n",
        "test_program(f_2, lambda x: (x + 2) ** x)\n",
        "test_program(f_3, lambda x: x ** 2 if x < 0 else (x ** 2 + 1) ** 0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 2: Finding Programs\n",
        "\n",
        "To begin with, we look into using enumeration to find programs. Since we don't have a set of programs to fit a distribution to, we start with a ``uniform PCFG'' (minor note: this is an ill-defined PCFG in this case since sampling from it has a high probability of divergence. it doesn't matter to the enumeration algorithm, however)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "dist_family = ns.BigramProgramDistributionFamily(dsl)\n",
        "uniform = dist_family.uniform()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can enumerate programs from this distribution by running the `dist_family.enumerate` command. This produces an infinite stream of programs, which we can limit with `islice` as below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "for prog, like in itertools.islice(dist_family.enumerate(uniform), 10):\n",
        "    print(ns.render_s_expression(prog), like)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also specify a minimum likelihood, and guarantee that we see all programs above that likelihood:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "for prog, like in dist_family.enumerate(uniform, min_likelihood=-5):\n",
        "    print(ns.render_s_expression(prog), like)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 2: Finding a program\n",
        "\n",
        "Finish the following function below, which, given a distribution, a list of inputs and a list of outputs, finds a program matching those inputs and outputs, within epsilon at all locations. It might be helpful to look at the `test_program` method above to see how to run programs. Important detail: you will want to handle errors and `nan` values gracefully. For this, we provide the `run_safely` function, that takes a function and input and runs it, returning `None` if its output is `nan` or an error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_safely(f, x):\n",
        "    try:\n",
        "        y = f(x)\n",
        "    except:\n",
        "        return None\n",
        "    if np.isnan(y):\n",
        "        return None\n",
        "    return y\n",
        "\n",
        "def find_program(dist, inputs, outputs, epsilon):\n",
        "    \"YOUR CODE HERE\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the following tests to ensure your implementation is correct:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_program_for_function(dist, fn, epsilon):\n",
        "    inputs = np.linspace(-2, 2)\n",
        "    outputs = fn(inputs)\n",
        "    return find_program(dist, inputs, outputs, epsilon)\n",
        "\n",
        "assert ns.render_s_expression(find_program_for_function(uniform, lambda x: x * 2, 0)) == '(lam (* ($0_0) (2)))'\n",
        "assert ns.render_s_expression(find_program_for_function(uniform, np.abs, 0.001)) == '(lam (sqrt (* ($0_0) ($0_0))))'\n",
        "assert ns.render_s_expression(find_program_for_function(uniform, lambda x: x + 0.05, 0.1)) == '(lam ($0_0))'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You will notice in the second test above, the enumerator came up with a \"creative\" solution to the absolute value problem. This is because this ended up being an easier to find solution than the more obvious `(lam (ite (< ($0_0) (0)) (- (0) ($0_0)) ($0_0)))`.\n",
        "\n",
        "The following cell will take slightly longer to run, but you can see that it is able to identify a solution for $\\cos^2 \\theta$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "ns.render_s_expression(find_program_for_function(uniform, lambda x: np.cos(x) ** 2, 0.001))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 3: Abstraction Learning\n",
        "\n",
        "We start by introducing a dataset of smoothed sequences. These sequences have values roughly in the range $[-2, 2]$ are generally smoothed. We generate this data below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_sequences = 1000\n",
        "len_sequences = 100\n",
        "xs = np.linspace(-10, 10, len_sequences)\n",
        "slack = 30\n",
        "stride = 5\n",
        "values = np.random.RandomState(1).rand(num_sequences, len_sequences + slack) * 4 - 2\n",
        "values = np.mean([values[:, i:i + len_sequences] for i in range(slack)], axis=0)\n",
        "values *= np.sqrt(slack)\n",
        "values = values[:, ::stride]\n",
        "xs = xs[::stride]\n",
        "\n",
        "plot_count = 3\n",
        "\n",
        "def plot_some_sequences():\n",
        "    for i in range(plot_count):\n",
        "        plt.plot(xs, values[i], color=f\"C{i}\", alpha=0.25)\n",
        "        plt.scatter(xs, values[i], color=f\"C{i}\", marker=\".\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_some_sequences()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We provide a function for finding the best program out of a list that matches a given data sequence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_all_programs(dsl, programs):\n",
        "    filtered_programs, evaluations = [], []\n",
        "    for prog in programs:\n",
        "        try:\n",
        "            actual_fn = dsl.compute(dsl.initialize(prog))\n",
        "        except:\n",
        "            continue\n",
        "        ys = []\n",
        "        for inp in xs:\n",
        "            y = run_safely(actual_fn, inp)\n",
        "            if y is None or not (-2 <= y <= 2):\n",
        "                break\n",
        "            ys.append(y)\n",
        "        else:\n",
        "            filtered_programs.append(prog)\n",
        "            evaluations.append(ys)\n",
        "    return filtered_programs, np.array(evaluations)\n",
        "\n",
        "def best_fits(dsl, family, dist):\n",
        "    programs = [prog for prog, _ in itertools.islice(family.enumerate(dist), 5000)]\n",
        "    programs = sorted(programs, key=lambda x: len(ns.render_s_expression(x)))\n",
        "    filtered_programs, ys = evaluate_all_programs(dsl, programs)\n",
        "    errors = ((ys[None] - values[:,None]) ** 2).sum(-1)\n",
        "    program_idxs = errors.argmin(1)\n",
        "    print(\"Mean error: \", errors.min(1).mean())\n",
        "    return [filtered_programs[i] for i in program_idxs]\n",
        "\n",
        "def plot_programs_against_data(dsl, best_programs):\n",
        "    plot_some_sequences()\n",
        "    best_programs = best_programs[:plot_count]\n",
        "    _, evals = evaluate_all_programs(dsl, best_programs)\n",
        "    for prog, ev in zip(best_programs, evals):\n",
        "        plt.plot(xs, ev, label=ns.render_s_expression(prog).replace(\"$\", r\"\\$\"))\n",
        "    plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we find the best programs among the first 50k enumerated programs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_programs = best_fits(dsl, dist_family, uniform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_programs_against_data(dsl, best_programs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 3A: Fitting a DSL\n",
        "\n",
        "Fit a function to the `best_programs`. Useful functions to know are `dist_family.fit_distribution` and `distribution.bound_minimum_likelihood`. Use a parameter of 0.01 as the minimum likelihood."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "fitted_dist = ______\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We then check the fit. This should lead to a lower mean error:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_programs_fitted = best_fits(dsl, dist_family, fitted_dist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_programs_against_data(dsl, best_programs_fitted)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 3B: Abstractions\n",
        "\n",
        "You can use the function `ns.compression.multi_step_compression` to get a new dsl and rewritten programs. Use this function to create a new DSL with 5 new abstractions and a new distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "abstraction_dsl, abstraction_family, abstraction_dist = ______\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can see your printed DSL here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(abstraction_dsl.render())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now can see how this effects our program fitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_programs_abstractions = best_fits(abstraction_dsl, abstraction_family, abstraction_dist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_programs_against_data(abstraction_dsl, best_programs_abstractions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 4: Bonus: Python DSL Subset\n",
        "\n",
        "This section does not contain any exercises, and exists only as a showcase of the Python DSL Subset feature of the neurosymbolic library.\n",
        "\n",
        "First, we have a method for converting Python code into s-expressions compatible with the neurosym library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "code = \"\"\"\n",
        "x = 2\n",
        "y = 2 + x\n",
        "z = x + y\n",
        "\"\"\"\n",
        "\n",
        "code_s = ns.python_to_type_annotated_ns_s_exp(code)\n",
        "ns.render_s_expression(code_s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We would like to be able to fit distributions to these programs, but unfortunately the Python DSL is infinite in our framework, as we do not support arbitrary leaves. Thus, we need to establish a DSL subset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "subset = ns.PythonDSLSubset.from_s_exps([code_s])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can then create Python DSL as such. Note that the DSL produced is quite large."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "dsl_python = ns.create_python_dsl(ns.python_dfa(), subset, \"M\")\n",
        "print(dsl_python.render())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can enumerate some programs from this DSL, adding in a `DefUseChainPreorderMask` which enforces that our distribution only produces programs where the def-use chains are all valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "python_family = ns.BigramProgramDistributionFamily(\n",
        "    dsl_python,\n",
        "    additional_preorder_masks=[\n",
        "        lambda dist, dsl: ns.python_def_use_mask.DefUseChainPreorderMask(\n",
        "            dist, dsl, ns.python_def_use_mask.DefUseMaskConfiguration(ns.python_dfa(), {})\n",
        "        )\n",
        "    ],\n",
        "    node_ordering=ns.python_def_use_mask.PythonNodeOrdering,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "python_dist = python_family.fit_distribution([code_s])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that in all the produced programs, def-use chains are preserved"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "for x, like in itertools.islice(python_family.enumerate(python_dist), 10):\n",
        "    print(ns.s_exp_to_python(x))\n",
        "    print(\"*\" * 100)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
