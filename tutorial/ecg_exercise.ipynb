{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neurosymbolic Software Tutorial - ECG Dataset\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/kavigupta/neurosym-lib/blob/main/tutorial/ecg_exercise.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "## Instruction\n",
    "- Navigating this notebook on Google Colab: There will be text blocks and code blocks throughout the notebook. The text blocks, such as this one, will contain instructions and questions for you to consider. The code blocks, such as the one below, will contain executible code. Sometimes you will have to modify the code blocks following the instructions in the text blocks. You can run the code block by either pressing control/cmd + enter or by clicking the arrow on left-hand side.\n",
    "- Saving Work: If you wish to save your work in this .ipynb, we recommend downloading the compressed repository from GitHub, unzipping it, uploading it to Google Drive, and opening this notebook from within Google Drive.\n",
    "\n",
    "## Notebook\n",
    "\n",
    "In this notebook, you will construct a DSL to analyze ECG data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asehgal/env/miniconda3/envs/neurosym-lib/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import neurosym as ns\n",
    "from neurosym.examples import near\n",
    "\n",
    "pl = ns.import_pytorch_lightning()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "We then load and plot some bouncing ball trajectories. Note that these trajectories are represented as a list `[x, y, vx, vy]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_npz(features_pth, label_pth):\n",
    "    assert os.path.exists(features_pth), f\"{features_pth} does not exist.\"\n",
    "    assert os.path.exists(label_pth), f\"{label_pth} does not exist.\"\n",
    "    X = np.load(features_pth)\n",
    "    y = np.load(label_pth)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def filter_multilabel(split):\n",
    "    x_fname = f\"ecg_exercise/x_{split}.npy\"\n",
    "    y_fname = f\"ecg_exercise/y_{split}.npy\"\n",
    "    X = np.load(x_fname)\n",
    "    y = np.load(y_fname)\n",
    "\n",
    "    mask = y.sum(-1) == 1\n",
    "\n",
    "    # filter\n",
    "    X = X[mask]\n",
    "    y = y[mask]\n",
    "\n",
    "    # normalize each column of X to [0, 1]\n",
    "    X = (X - X.min(0)) / (X.max(0) - X.min(0))\n",
    "\n",
    "    # save as filtered\n",
    "    np.save(x_fname.replace(f\"{split}\", f\"{split}_filtered\"), X.astype(np.float32))\n",
    "    np.save(y_fname.replace(f\"{split}\", f\"{split}_filtered\"), y.astype(np.float32))\n",
    "\n",
    "\n",
    "filter_multilabel(\"train\")\n",
    "filter_multilabel(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_factory = lambda train_seed: ns.DatasetWrapper(\n",
    "    ns.DatasetFromNpy(\n",
    "        f\"ecg_exercise/x_train_filtered.npy\",\n",
    "        f\"ecg_exercise/y_train_filtered.npy\",\n",
    "        train_seed,\n",
    "    ),\n",
    "    ns.DatasetFromNpy(\n",
    "        f\"ecg_exercise/x_test_filtered.npy\",\n",
    "        f\"ecg_exercise/y_test_filtered.npy\",\n",
    "        None,\n",
    "    ),\n",
    "    batch_size=200,\n",
    "    num_workers=0,\n",
    ")\n",
    "datamodule = dataset_factory(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_trajectory(trajectory, color):\n",
    "    # TODO: What is a good way to visualize the trajectory?\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    plot_trajectory(datamodule.train.inputs[:], f\"C{i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: DSL\n",
    "\n",
    "Fill in the `bounce_dsl` to parameterize the space of functions that could represent the trajectories of bouncing balls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datamodule.train.get_io_dims()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_selector_all_feat(x, channel, typ):\n",
    "    x = x.reshape(-1, 12, 6, 2)\n",
    "    typ_idx = torch.full(\n",
    "        size=(x.shape[0],), fill_value=(0 if typ == \"interval\" else 1), device=x.device\n",
    "    )\n",
    "    channel_mask = channel(x.reshape(-1, 144))  # [B, 12]\n",
    "    masked_x = (x * channel_mask[..., None, None]).sum(1)\n",
    "    return masked_x[torch.arange(x.shape[0]), :, typ_idx]\n",
    "\n",
    "# def subset_selector_all_feat(x, channel, typ):\n",
    "#     x = x.reshape(-1, 12, 6, 2)\n",
    "#     typ_idx = torch.full(\n",
    "#         size=(x.shape[0],), fill_value=(0 if typ == \"interval\" else 1), device=x.device\n",
    "#     )\n",
    "#     channel_mask = channel(x.reshape(-1, 144))  # [B, 12]\n",
    "#     masked_x = (x * channel_mask[..., None, None]).sum(1)\n",
    "#     return masked_x[torch.arange(x.shape[0]), :, typ_idx]\n",
    "\n",
    "# def guard_callables(fn, **kwargs):\n",
    "#     is_callable = [callable(kwargs[k]) for k in kwargs]\n",
    "#     if any(is_callable):\n",
    "#         return lambda z: fn(\n",
    "#             **{\n",
    "#                 k: (kwargs[k](z) if is_callable[i] else kwargs[k])\n",
    "#                 for i, k in enumerate(kwargs)\n",
    "#             }\n",
    "#         )\n",
    "#     else:\n",
    "#         return fn(**kwargs)\n",
    "\n",
    "# def filter_constants(x):\n",
    "#     match x:\n",
    "#         case ns.ArrowType(a, b):\n",
    "#             return filter_constants(a) and filter_constants(b)\n",
    "#         case ns.AtomicType(a):\n",
    "#             return a not in [\"channel\", \"feature\"]\n",
    "#         case _:\n",
    "#             return True\n",
    "\n",
    "# def filter_same_type(x):\n",
    "#     raise NotImplementedError\n",
    "\n",
    "# def ecg_dsl():\n",
    "#     L = 144\n",
    "#     O = 2\n",
    "#     F = 6\n",
    "#     dslf = ns.DSLFactory(L=L, O=O, F=F, max_overall_depth=10)\n",
    "#     dslf.typedef(\"fInp\", \"{f, $L}\")\n",
    "#     dslf.typedef(\"fOut\", \"{f, $O}\")\n",
    "#     dslf.typedef(\"fFeat\", \"{f, $F}\")\n",
    "\n",
    "#     for i in range(12):\n",
    "#         dslf.concrete(\n",
    "#             f\"channel_{i}\",\n",
    "#             \"() -> channel\",\n",
    "#             # onehot vector where the ith element is 1\n",
    "#             # lambda: lambda x: torch.full(\n",
    "#             #     tuple(x.shape[:-1] + (1,)), i, device=x.device\n",
    "#             # ),\n",
    "#             lambda: lambda x: torch.nn.functional.one_hot(\n",
    "#                 torch.full(tuple(x.shape[:-1]), i, device=x.device, dtype=torch.long),\n",
    "#                 num_classes=12,\n",
    "#             ),\n",
    "#         )\n",
    "\n",
    "#     dslf.concrete(\n",
    "#         \"select_interval\",\n",
    "#         \"(channel) -> ($fInp) -> $fFeat\",\n",
    "#         lambda ch: lambda x: subset_selector_all_feat(x, ch, \"interval\"),\n",
    "#     )\n",
    "\n",
    "#     dslf.concrete(\n",
    "#         \"select_amplitude\",\n",
    "#         \"(channel) -> ($fInp) -> $fFeat\",\n",
    "#         lambda ch: lambda x: subset_selector_all_feat(x, ch, \"amplitude\"),\n",
    "#     )\n",
    "\n",
    "#     dslf.filtered_type_variable(\"num\", lambda x: filter_constants(x))\n",
    "#     dslf.filtered_type_variable(\"num\", lambda x: filter_same_type(x))\n",
    "#     dslf.concrete(\n",
    "#         \"add\",\n",
    "#         \"(%num, %num) -> %num\",\n",
    "#         lambda x, y: guard_callables(fn=lambda x, y: x + y, x=x, y=y),\n",
    "#     )\n",
    "#     dslf.concrete(\n",
    "#         \"mul\",\n",
    "#         \"(%num, %num) -> %num\",\n",
    "#         lambda x, y: guard_callables(fn=lambda x, y: x * y, x=x, y=y),\n",
    "#     )\n",
    "\n",
    "#     dslf.parameterized(\n",
    "#         \"linear\",\n",
    "#         \"(($fInp) -> $fFeat) -> $fInp -> {f, 1}\",\n",
    "#         lambda f, lin: lambda x: lin(f(x)),\n",
    "#         dict(lin=lambda: nn.Linear(F, 1)),\n",
    "#     )\n",
    "\n",
    "#     dslf.parameterized(\n",
    "#         \"output\",\n",
    "#         \"(($fInp) -> $fFeat) -> $fInp -> $fOut\",\n",
    "#         lambda f, lin: lambda x: lin(f(x)),\n",
    "#         dict(lin=lambda: nn.Linear(F, O)),\n",
    "#     )\n",
    "\n",
    "#     # dslf.concrete(\"ite_ab\", \"(#a -> f, #a -> #b, #a -> #b) -> #a -> #b\", near.operations.ite_torch)\n",
    "#     # dslf.concrete(\"ite_aa\", \"(#a -> f, #a -> #a, #a -> #a) -> #a -> #a\", near.operations.ite_torch)\n",
    "#     # dslf.concrete(\n",
    "#     #     \"map\", \"(#a -> #b) -> [#a] -> [#b]\", lambda f: lambda x: near.operations.map_torch(f, x)\n",
    "#     # )\n",
    "#     dslf.prune_to(\"($fInp) -> $fOut\")\n",
    "#     return dslf.finalize()\n",
    "# dsl = ecg_dsl()\n",
    "\n",
    "\n",
    "from neurosym.dsl.dsl_factory import DSLFactory\n",
    "from neurosym.examples.near.operations.basic import ite_torch\n",
    "from neurosym.types.type import ArrowType, AtomicType\n",
    "\n",
    "\n",
    "def ecg_dsl(input_dim, output_dim, max_overall_depth=6):\n",
    "    \"\"\"Creates a domain-specific language (DSL) for neural symbolic computation.\n",
    "\n",
    "    This function sets up a DSL with basic operations like addition, multiplication,\n",
    "    and folds, as well as neural network components like linear layers.\n",
    "\n",
    "    Args:\n",
    "        input_dim (int): The dimensionality of the input features.\n",
    "        output_dim (int): The dimensionality of the output features.\n",
    "\n",
    "    Returns:\n",
    "        DSLFactory: An instance of `DSLFactory` with the defined operations and types.\n",
    "    \"\"\"\n",
    "    feature_dim = 6\n",
    "    dslf = DSLFactory(\n",
    "        I=input_dim, O=output_dim, F=feature_dim, max_overall_depth=max_overall_depth\n",
    "    )\n",
    "    dslf.typedef(\"fInp\", \"{f, $I}\")\n",
    "    dslf.typedef(\"fOut\", \"{f, $O}\")\n",
    "    dslf.typedef(\"fFeat\", \"{f, $F}\")\n",
    "\n",
    "    # \"add(select_interval(channel_2), select_amplitude(channel_8))\n",
    "    # \"add(select_interval_channel_2, select_amplitude_channel_8)\n",
    "    # \"add(??, ??)\"\n",
    "\n",
    "    for i in range(12):\n",
    "        dslf.concrete(\n",
    "            f\"channel_{i}\",\n",
    "            \"() -> channel\",\n",
    "            # onehot vector where the ith element is 1\n",
    "            # lambda: lambda x: torch.full(\n",
    "            #     tuple(x.shape[:-1] + (1,)), i, device=x.device\n",
    "            # ),\n",
    "            lambda: lambda x: torch.nn.functional.one_hot(\n",
    "                torch.full(tuple(x.shape[:-1]), i, device=x.device, dtype=torch.long),\n",
    "                num_classes=12,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    # for i in range(6):\n",
    "    #     dslf.concrete(\n",
    "    #         f\"feature_{i}\",\n",
    "    #         \"() -> () -> feature\",\n",
    "    #         lambda: lambda x: torch.full(\n",
    "    #             tuple(x.shape[:-1] + (1,)), i, device=x.device\n",
    "    #         ),\n",
    "    #     )\n",
    "\n",
    "    dslf.concrete(\n",
    "        \"select_interval\",\n",
    "        \"(channel) -> ($fInp) -> $fFeat\",\n",
    "        lambda ch: lambda x: subset_selector_all_feat(x, ch, \"interval\"),\n",
    "    )\n",
    "\n",
    "    dslf.concrete(\n",
    "        \"select_amplitude\",\n",
    "        \"(channel) -> ($fInp) -> $fFeat\",\n",
    "        lambda ch: lambda x: subset_selector_all_feat(x, ch, \"amplitude\"),\n",
    "    )\n",
    "\n",
    "    def guard_callables(fn, **kwargs):\n",
    "        is_callable = [callable(kwargs[k]) for k in kwargs]\n",
    "        if any(is_callable):\n",
    "            return lambda z: fn(\n",
    "                **{\n",
    "                    k: (kwargs[k](z) if is_callable[i] else kwargs[k])\n",
    "                    for i, k in enumerate(kwargs)\n",
    "                }\n",
    "            )\n",
    "        else:\n",
    "            return fn(**kwargs)\n",
    "\n",
    "    def filter_constants(x):\n",
    "        match x:\n",
    "            case ArrowType(a, b):\n",
    "                return filter_constants(a) and filter_constants(b)\n",
    "            case AtomicType(a):\n",
    "                return a not in [\"channel\", \"feature\"]\n",
    "            case _:\n",
    "                return True\n",
    "\n",
    "    # def filter_same_type(x):\n",
    "    #     raise NotImplementedError\n",
    "\n",
    "    dslf.filtered_type_variable(\"num\", lambda x: filter_constants(x))\n",
    "    # dslf.filtered_type_variable(\"num\", lambda x: filter_same_type(x))\n",
    "    dslf.concrete(\n",
    "        \"add\",\n",
    "        \"(%num, %num) -> %num\",\n",
    "        lambda x, y: guard_callables(fn=lambda x, y: x + y, x=x, y=y),\n",
    "    )\n",
    "    dslf.concrete(\n",
    "        \"mul\",\n",
    "        \"(%num, %num) -> %num\",\n",
    "        lambda x, y: guard_callables(fn=lambda x, y: x * y, x=x, y=y),\n",
    "    )\n",
    "    # dslf.concrete(\n",
    "    #     \"sub\",\n",
    "    #     \"(%num, %num) -> %num\",\n",
    "    #     lambda x, y: guard_callables(fn=lambda x, y: x - y, x=x, y=y),\n",
    "    # )\n",
    "\n",
    "    # dslf.parameterized(\"linear_bool\", \"() -> $fFeat -> $fFeat\", lambda lin: lin, dict(lin=lambda: nn.Linear(input_dim, 1)))\n",
    "    dslf.parameterized(\n",
    "        \"linear\",\n",
    "        \"(($fInp) -> $fFeat) -> $fInp -> {f, 1}\",\n",
    "        lambda f, lin: lambda x: lin(f(x)),\n",
    "        dict(lin=lambda: nn.Linear(feature_dim, 1)),\n",
    "    )\n",
    "\n",
    "    dslf.parameterized(\n",
    "        \"output\",\n",
    "        \"(($fInp) -> $fFeat) -> $fInp -> $fOut\",\n",
    "        lambda f, lin: lambda x: lin(f(x)),\n",
    "        dict(lin=lambda: nn.Linear(feature_dim, output_dim)),\n",
    "    )\n",
    "\n",
    "    # dslf.concrete(\"iteA\", \"(#a -> $fFeat, #a -> #a, #a -> #a) -> #a -> #a\", lambda cond, fx, fy: ite_torch(cond, fx, fy))\n",
    "    dslf.concrete(\n",
    "        \"ite\",\n",
    "        \"(#a -> {f, 1}, #a -> #b, #a -> #b) -> #a -> #b\",\n",
    "        lambda cond, fx, fy: ite_torch(cond, fx, fy),\n",
    "        # lambda cond, fx, fy: guard_callables(fn=partial(ite_torch, condition=cond), if_true=fx, if_else=fy),\n",
    "    )\n",
    "    # dslf.concrete(\"map\", \"(#a -> #b) -> [#a] -> [#b]\", lambda f: lambda x: map_torch(f, x))\n",
    "    # dslf.concrete(\"compose\", \"(#a -> #b, #b -> #c) -> #a -> #c\", lambda f, g: lambda x: g(f(x)))\n",
    "    # dslf.concrete(\"fold\", \"((#a, #a) -> #a) -> [#a] -> #a\", lambda f: lambda x: fold_torch(f, x))\n",
    "\n",
    "    dslf.prune_to(\"($fInp) -> $fOut\")\n",
    "    return dslf.finalize(), dslf.t\n",
    "\n",
    "input_dim, output_dim = 144, 9\n",
    "\n",
    "dsl, dsl_type_env = ecg_dsl(input_dim=input_dim, output_dim=output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DSL Printout\n",
    "\n",
    "See your DSL printed below, and ensure it is what you would expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      channel_0 :: () -> channel\n",
      "      channel_1 :: () -> channel\n",
      "      channel_2 :: () -> channel\n",
      "      channel_3 :: () -> channel\n",
      "      channel_4 :: () -> channel\n",
      "      channel_5 :: () -> channel\n",
      "      channel_6 :: () -> channel\n",
      "      channel_7 :: () -> channel\n",
      "      channel_8 :: () -> channel\n",
      "      channel_9 :: () -> channel\n",
      "     channel_10 :: () -> channel\n",
      "     channel_11 :: () -> channel\n",
      "select_interval :: channel -> {f, 144} -> {f, 6}\n",
      "select_amplitude :: channel -> {f, 144} -> {f, 6}\n",
      "            add :: (%num, %num) -> %num\n",
      "            mul :: (%num, %num) -> %num\n",
      "            ite :: (#a -> {f, 1}, #a -> #b, #a -> #b) -> #a -> #b\n",
      "    linear[lin] :: ({f, 144} -> {f, 6}) -> {f, 144} -> {f, 1}\n",
      "    output[lin] :: ({f, 144} -> {f, 6}) -> {f, 144} -> {f, 9}\n"
     ]
    }
   ],
   "source": [
    "print(dsl.render())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up Neural DSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = ns.TypeDefiner(L=input_dim, O=output_dim)\n",
    "t.typedef(\"fL\", \"{f, $L}\")\n",
    "neural_dsl = near.NeuralDSL.from_dsl(\n",
    "    dsl=dsl,\n",
    "    modules={\n",
    "        **near.create_modules(\n",
    "            \"mlp\",\n",
    "            [\n",
    "                dsl_type_env(\"($fInp) -> $fInp\"),\n",
    "                dsl_type_env(\"($fInp) -> $fOut\"),\n",
    "                dsl_type_env(\"($fInp) -> $fFeat\"),\n",
    "                dsl_type_env(\"($fInp) -> {f, 1}\"),\n",
    "                #  t(\"([$fI]) -> [$fI]\"), t(\"([$fI]) -> [$fO]\")\n",
    "            ],\n",
    "            near.mlp_factory(hidden_size=10),\n",
    "        ),\n",
    "        **near.create_modules(\n",
    "            \"constant_int\",\n",
    "            [dsl_type_env(\"() -> channel\")],\n",
    "            near.selector_factory(input_dim=input_dim),\n",
    "            known_atom_shapes=dict(channel=(12,), feature=(6,)),\n",
    "        ),\n",
    "    },\n",
    ")\n",
    "logging.getLogger(\"pytorch_lightning.utilities.rank_zero\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"pytorch_lightning.accelerators.cuda\").setLevel(logging.WARNING)\n",
    "\n",
    "def cross_entropy_callback(predicitons, targets):\n",
    "    return torch.nn.functional.cross_entropy(predicitons, targets)\n",
    "\n",
    "trainer_cfg = near.NEARTrainerConfig(\n",
    "    lr=1e-2,\n",
    "    max_seq_len=300,\n",
    "    n_epochs=30,\n",
    "    num_labels=output_dim,\n",
    "    train_steps=len(datamodule.train),\n",
    "    loss_callback=cross_entropy_callback,\n",
    "    scheduler=\"cosine\",\n",
    "    optimizer=torch.optim.Adam,\n",
    ")\n",
    "\n",
    "validation_cost = near.ValidationCost(\n",
    "    neural_dsl=neural_dsl,\n",
    "    trainer_cfg=trainer_cfg,\n",
    "    datamodule=datamodule,\n",
    "    accelerator=\"cuda\",\n",
    "    devices=1,\n",
    "    callbacks=[\n",
    "        pl.callbacks.EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=5, mode='min')\n",
    "    ],\n",
    "    enable_progress_bar=False,\n",
    "    enable_model_summary=False,\n",
    "    progress_by_epoch=True,\n",
    ")\n",
    "\n",
    "g = near.near_graph(\n",
    "    neural_dsl,\n",
    "    ns.parse_type(\n",
    "        s=\"({f, $L}) -> {f, $O}\", env=ns.TypeDefiner(L=input_dim, O=output_dim)\n",
    "    ),\n",
    "    is_goal=neural_dsl.program_has_no_holes,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run NEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import redirect_stdout, redirect_stderr\n",
    "\n",
    "with open('ecg_exercise/output3.logs', 'w') as f:\n",
    "    with redirect_stdout(f):\n",
    "        with redirect_stderr(f):\n",
    "            iterator = ns.search.bounded_astar(g, validation_cost, max_depth=16)\n",
    "            # iterator = ns.search.bounded_astar_async(g, validation_cost, max_depth=16, max_workers=5)\n",
    "            best_program_nodes = []\n",
    "            # Let's collect the top three programs\n",
    "            while len(best_program_nodes) <= 2:\n",
    "                try:\n",
    "                    node = next(iterator)\n",
    "                    cost = validation_cost(node)\n",
    "                    best_program_nodes.append((node, cost))\n",
    "                    print(\"Got another program\")\n",
    "                except StopIteration:\n",
    "                    print(\"No more programs found.\")\n",
    "                    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 3 Programs\n",
    "\n",
    "The code below assumes you found some top 3 programs and stored them in the best_program_nodes variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_program_nodes = sorted(best_program_nodes, key=lambda x: x[1])\n",
    "for i, (node, cost) in enumerate(best_program_nodes):\n",
    "    print(\n",
    "        \"({i}) Cost: {cost:.4f}, {program}\".format(\n",
    "            i=i, program=ns.render_s_expression(node.program), cost=cost\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below is set up to further fine tune the program, test it, and return a set of values produced by it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testProgram(best_program_node):\n",
    "    module = near.TorchProgramModule(\n",
    "        dsl=neural_dsl, program=best_program_node[0].program\n",
    "    )\n",
    "    pl_model = near.NEARTrainer(module, config=trainer_cfg)\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=4000,\n",
    "        devices=\"auto\",\n",
    "        accelerator=\"cpu\",\n",
    "        enable_checkpointing=False,\n",
    "        logger=False,\n",
    "        callbacks=[\n",
    "            pl.callbacks.EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=5)\n",
    "        ],\n",
    "        enable_progress_bar=False,\n",
    "    )\n",
    "\n",
    "    trainer.fit(pl_model, datamodule.train_dataloader(), datamodule.val_dataloader())\n",
    "    # T = 100\n",
    "    # path = np.zeros((T, 4))\n",
    "    # X = torch.tensor(\n",
    "    #     np.array([0.21413583, 4.4062634, 3.4344807, 0.12440437]), dtype=torch.float32\n",
    "    # )\n",
    "    # for t in range(T):\n",
    "    #     path[t, :] = X.detach().numpy()\n",
    "    #     Y = module(X.unsqueeze(0)).squeeze(0)\n",
    "    #     X = Y\n",
    "    # return path\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # We generate trajectories for the top 2 programs.\n",
    "# trajectory = testProgram(best_program_nodes[0])\n",
    "# trajectoryb = testProgram(best_program_nodes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(8, 8))\n",
    "\n",
    "# plot_trajectory(trajectory, \"C0\")\n",
    "# plot_trajectory(trajectoryb, \"C1\")\n",
    "# plot_trajectory(datamodule.train.inputs[0], \"black\")\n",
    "\n",
    "# plt.title(\"Bouncing ball (ground truth in black)\")\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
